{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39b76a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\julian.auriac\\\\DocLoc\\\\github\\\\BigDataHadoopSparkDaskCourse\\\\TPs\\\\Project\\\\Project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d960d455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in c:\\users\\julian.auriac\\.conda\\envs\\pourdask\\lib\\site-packages (2.14.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\julian.auriac\\.conda\\envs\\pourdask\\lib\\site-packages (from imageio) (1.21.5)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\julian.auriac\\.conda\\envs\\pourdask\\lib\\site-packages (from imageio) (8.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio\n",
    "import imageio\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7430ec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "import dask.dataframe as dd\n",
    "from dask import compute\n",
    "import dask_image.imread\n",
    "import dask_image.ndfilters\n",
    "import dask_image.ndmeasure\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a92e92cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImg(path):\n",
    "    img = imageio.imread(path)\n",
    "    im = np.array(img,dtype='uint8')\n",
    "    nb_partitions = 8\n",
    "    chunk_size = [img.shape[1]//8, img.shape[1], img.shape[2]]\n",
    "    imgReturn = da.from_array(im, chunks=chunk_size)\n",
    "    return imgReturn\n",
    "\n",
    "def writeImg(path,buf):\n",
    "    imageio.imwrite(path,buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f117439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dask_image.imread\n",
    "#x = dask_image.imread.imread('./data/lena_noisy.jpg')\n",
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a06853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB PARTITIONS :  8\n"
     ]
    }
   ],
   "source": [
    "data_dir=\"./data/\"\n",
    "file = os.path.join(data_dir,'lena_noisy.jpg')\n",
    "img_buf=readImg(file)\n",
    "#import dask_image.imread\n",
    "#img_buf = dask_image.imread.imread('./data/lena_noisy.jpg')\n",
    "img_buf\n",
    "nx=img_buf.shape[0]\n",
    "ny=img_buf.shape[1]\n",
    "\n",
    "###########################################################################\n",
    "#\n",
    "# SPLIT IMAGES IN NB_PARTITIONS PARTS\n",
    "nb_partitions = 8\n",
    "print(\"NB PARTITIONS : \",nb_partitions)\n",
    "data=[]\n",
    "begin=0\n",
    "block_size=nx/nb_partitions\n",
    "for ip in range(nb_partitions):\n",
    "    end=min(begin+block_size,nx)\n",
    "    data.append([ip,begin,end,img_buf])\n",
    "    begin=end\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "#\n",
    "# CREATE DASK CLIENT\n",
    "client = Client(n_workers=8)\n",
    "#from dask.distributed import LocalCluster, Client\n",
    "#cluster = LocalCluster()\n",
    "#client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dab957b",
   "metadata": {},
   "source": [
    "def part_median_filter(local_data):\n",
    "    print(local_data)\n",
    "    part_id = local_data[0]\n",
    "    first   = local_data[1]\n",
    "    end     = local_data[2]\n",
    "    buf     = local_data[3]\n",
    "    nx=buf.shape[0]\n",
    "    ny=buf.shape[1]\n",
    "    \n",
    "    index = (part_id*ny//nb_partitions)\n",
    "    if part_id == 0:\n",
    "        temp = img_buf[index:(index)+ny//nb_partitions+1].copy()\n",
    "    elif part_id == nb_partitions-1:\n",
    "        temp = img_buf[index-1:(index)+ny//nb_partitions].copy()\n",
    "    else:\n",
    "        temp = img_buf[index-1:(index)+ny//nb_partitions+1].copy()\n",
    "\n",
    "    new_buf = np.zeros(temp.shape)\n",
    "\n",
    "    for i in range(0,temp.shape[0]-1):\n",
    "        for j in range(0,temp.shape[1]-1):\n",
    "            new_buf[i,j]=np.median([temp[i,j,:],temp[i+1,j,:],temp[i,j+1,:],temp[i+1,j+1,:],temp[i-1,j,:],temp[i,j-1,:],temp[i-1,j-1,:],temp[i+1,j-1,:],temp[i-1,j+1,:]],axis=0)\n",
    "        new_buf[i,temp.shape[1]-1]=np.median([temp[i,j,:],temp[i,j+1,:],temp[i-1,j,:],temp[i,j-1,:],temp[i-1,j-1,:],temp[i-1,j+1,:]],axis=0)\n",
    "        \n",
    "    \n",
    "    if part_id == 0:\n",
    "        new_buf = new_buf[:-1].copy()\n",
    "    elif part_id == nb_partitions-1:\n",
    "        new_buf = new_buf[1:].copy()\n",
    "        for j in range(0,temp.shape[1]-1):\n",
    "            new_buf[ny//nb_partitions-1,j]=np.median([temp[i,j,:],temp[i+1,j,:],temp[i-1,j,:],temp[i,j-1,:],temp[i-1,j-1,:],temp[i+1,j-1,:]],axis=0)\n",
    "    else:\n",
    "        new_buf = new_buf[1:-1].copy()\n",
    "    \n",
    "    return new_buf #part_id,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d164196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_median_filter(local_img):\n",
    "    nx=local_img.shape[0]\n",
    "    ny=local_img.shape[1]\n",
    "    \n",
    "    ##########################################\n",
    "    #\n",
    "    # TODO COMPUTE MEDIAN FILTER\n",
    "    #\n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            median_list = []\n",
    "            \n",
    "            if i != 0 and j != 0:\n",
    "                median_list.append(local_img[i-1,j-1])\n",
    "            if i != 0:\n",
    "                median_list.append(local_img[i-1,j])\n",
    "            if i != 0 and j != ny-1:\n",
    "                median_list.append(local_img[i-1,j+1])\n",
    "            if j != 0:\n",
    "                median_list.append(local_img[i,j-1])\n",
    "                \n",
    "            median_list.append(local_img[i,j])\n",
    "            \n",
    "            if j != ny-1:\n",
    "                median_list.append(local_img[i,j+1])\n",
    "            if i != nx-1 and j != 0:\n",
    "                median_list.append(local_img[i+1,j-1])\n",
    "            if i != nx-1:\n",
    "                median_list.append(local_img[i+1,j])\n",
    "            if i != nx-1 and j != ny-1:\n",
    "                median_list.append(local_img[i+1,j+1])\n",
    "            \n",
    "            if 1 == 2:\n",
    "                local_img[i, j] = np.median(median_list)\n",
    "            else:\n",
    "                local_img[i, j, :] = np.median(median_list, axis=0)\n",
    "    ##########################################\n",
    "    #\n",
    "    # RETURN LOCAL IMAGE PART\n",
    "    #\n",
    "    return local_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04ab2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "#\n",
    "# PARALLEL MEDIAN FILTER COMPUTATION\n",
    "#result_rdd = data_rdd.map(part_median_filter)\n",
    "#result_data = result_rdd.collect()\n",
    "\n",
    "import joblib\n",
    "with joblib.parallel_backend('dask'):\n",
    "    #result_rdd = data.map(part_median_filter)\n",
    "    #result_data = result_rdd.compute()\n",
    "    new_img_buf = img_buf.map_overlap(part_median_filter, depth=(1, img_buf.shape[1])).compute()\n",
    "\n",
    "#new_img_buf = img_buf.map_overlap(part_median_filter, depth=(1, img_buf.shape[1])).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efd3bb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE NEW PICTURE FILE\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "#\n",
    "# COMPUTE NEW IMAGE RESULTS FROM RESULT RDD\n",
    "# TODO\n",
    "#new_img_buf = []\n",
    "#for part in result_data:\n",
    "#    new_img_buf.append(part[1])\n",
    "\n",
    "#new_img_buf = np.vstack(new_img_buf)\n",
    "    \n",
    "print('CREATE NEW PICTURE FILE')\n",
    "filter_file = os.path.join(data_dir,'lena_filter.jpg')\n",
    "writeImg(filter_file,new_img_buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a18af6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
